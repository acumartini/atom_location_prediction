\section{Highlevel Architecture}
\label{architecture}

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{arch.png}
\caption{High Level Data Flow Architecture Diagram}
\label{fig:arch}
\end{center}
\end{figure}

\noindent Figure 1 shows a block level diagram of the project data flow. There are three main components to the solution.
\begin{description}
\item[Simulation] 
\item[Machine Learning] Test multiple machine learning algorithms to find and optimize a strong predictive model.
\item[Visualization]
\end{description}

\subsection{Simulation}
The essence of the simulation is starting with a flourescent atom at a chosen location, and then simulating how light emitted from the atom appears on the CCD. There are two approaches to simulating the generation of CCD images from a given atom location.

The first is a classical raytracing approach. Rays are emitted in a random direction from the atom, and obey refraction via Snell's Law as they pass interfaces between different materials. The rays also contain phase information for the purposes of determining interference. When the rays intersect with the CCD plane, we increment an array value cooresponding to which CCD pixel it hit.

The second approach is a full simulation of the linear wave equation. This is a full 3D simulation, and is much more computationally intensive. A field discretized into $~200\times 200\times 1000$ is given an initial value of zero everywhere except for a peak at our atom location, and then is stepped forward in time according to the linear wave equation. The essence of this algorithm is basic matrix multiplication, but with very large sparse matrices.

%The core of the simulator is a basic physics simulation. This N-body simulation will track projectiles and vehicles within the world and apply basic Newtonian physics. The simulator will expose the current location of each simulated object at regular intervals as a list of 3D cartesian coordinates and object radii. This stream will be sent using the FOSA format. The simulator will also take in a stream of BDS actions and add projectiles to the simulation as appropriate. The simulator also enforces some sanity rules regarding object motion and provides some basic flight paths for UFOs.

\subsection{Machine Learning}
We will train and test multiple machine learning algorithms on the simulated images by splitting the training data into a training and validation set.  The validation set will be used to determine the best algorithm for this application and then to tune its parameters.  The final classifier will be used to generate probabilistic predictions for the test set of actual CCD images.
 
%AKWDS will take the FOSA stream of object locations and attempt to formulate some tracking of the objects (object A with location $L$ last time step is at location $L'$ this time step). This will be used to help estimate the future location of the object so that targets can be lead correctly for firing. AKWDS will then select a set of object to fire at and set of cannons to fire from and send the needed information via the BDS stream.

\subsection{Visualization}
Visualization is particularly important for visualizing three dimensional volumes, and it may become essential for feedback as to whether our simulations are functioning properly, and for our presenting our project results. However, our project focus is not on programming the visualization methods ourselves, but using existing tools such as Visit or ParaView.

The main items to be visualized are the field generated from the differential equation solvers, and the CCD images (which are a cross section of the field). We can also use these tools for post processing on the image data to highlight features for the benefit of the machine learning algorithm.

%Visualization is not a core component of the project deliverable. However AKWDS debugging and demonstration will be very difficult without providing some animation of the system behavior. A visualizer, online or post-hoc, that works from the FOSA stream will be provided to help validate the software.

%\subsection{Data Reduction and Storage}

%We will save the output files onto each node while the simulation is running, and then gather them together on a single head node afterwards. This gives us less of a bottleneck on a single hard drive. During the simulation, the output files will be stored locally on each node, split into files according to the data handled by each node and by the timestep (and perhaps by chunk).

%Addtionally, we can reduce the data size pretty easily I think. It's more work to distribute, and would make our system run faster (maybe even substantially depending on how things pan out). We'll probably be limited by IO, so this actually would be a quick way to improve the speed. Lower priority... 

\subsection{Data Format}
The data will be formatted in the standard Visualization Tool Kit (VTK) format. We will use a regular regtagonal structured grid.
